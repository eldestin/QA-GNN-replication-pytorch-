{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport networkx as nx\nimport nltk\nimport json\nimport math\nfrom multiprocessing import cpu_count\nimport tqdm\nimport spacy","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:55:36.000288Z","iopub.execute_input":"2022-05-03T05:55:36.000995Z","iopub.status.idle":"2022-05-03T05:55:46.551858Z","shell.execute_reply.started":"2022-05-03T05:55:36.000855Z","shell.execute_reply":"2022-05-03T05:55:46.550966Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"relation_groups = [\n    'atlocation/locatednear',\n    'capableof',\n    'causes/causesdesire/*motivatedbygoal',\n    'createdby',\n    'desires',\n    'antonym/distinctfrom',\n    'hascontext',\n    'hasproperty',\n    'hassubevent/hasfirstsubevent/haslastsubevent/hasprerequisite/entails/mannerof',\n    'isa/instanceof/definedas',\n    'madeof',\n    'notcapableof',\n    'notdesires',\n    'partof/*hasa',\n    'relatedto/similarto/synonym',\n    'usedfor',\n    'receivesaction',\n]\n\nmerged_relations = [\n    'antonym',\n    'atlocation',\n    'capableof',\n    'causes',\n    'createdby',\n    'isa',\n    'desires',\n    'hassubevent',\n    'partof',\n    'hascontext',\n    'hasproperty',\n    'madeof',\n    'notcapableof',\n    'notdesires',\n    'receivesaction',\n    'relatedto',\n    'usedfor',\n]\n\nrelation_text = [\n    'is the antonym of',\n    'is at location of',\n    'is capable of',\n    'causes',\n    'is created by',\n    'is a kind of',\n    'desires',\n    'has subevent',\n    'is part of',\n    'has context',\n    'has property',\n    'is made of',\n    'is not capable of',\n    'does not desires',\n    'is',\n    'is related to',\n    'is used for',\n]","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:57:22.479287Z","iopub.execute_input":"2022-05-03T05:57:22.479579Z","iopub.status.idle":"2022-05-03T05:57:22.487443Z","shell.execute_reply.started":"2022-05-03T05:57:22.479548Z","shell.execute_reply":"2022-05-03T05:57:22.486742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_merge_relation():\n    '''\n    This function create a mapping, that map each multirelation to the toppest relation:\n    e.g.: atlocation/locatednear will map both atlocation, locatednear to atlocation relation\n    '''\n    rel_mapping = {}\n    for rel in relation_groups:\n#         print(rel)\n#         print(rel.strip().split(\"/\"))\n        ls = rel.strip().split(\"/\")\n        true_rel = ls[0]\n        for l in ls:\n            if l.startswith(\"*\"):\n                rel_mapping[l[1:]] = \"*\"+true_rel\n            else:\n                rel_mapping[l] = true_rel\n    return rel_mapping\ndef del_pos(s):\n    \"\"\"\n    Deletes part-of-speech encoding from an entity string, if present.\n    :param s: Entity string.\n    :return: Entity string with part-of-speech encoding removed.\n    \"\"\"\n    if s.endswith(\"/n\") or s.endswith(\"/a\") or s.endswith(\"/v\") or s.endswith(\"/r\"):\n        s = s[:-2]\n    return s","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:57:27.770697Z","iopub.execute_input":"2022-05-03T05:57:27.771432Z","iopub.status.idle":"2022-05-03T05:57:27.780947Z","shell.execute_reply.started":"2022-05-03T05:57:27.771388Z","shell.execute_reply":"2022-05-03T05:57:27.779933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def retrieve_eng(cpnet_path, output_path, output_vocab_path):\n    '''\n    This function retrieve english triples (head and tail are all english),\n    with following format:\n        <relation><head><tail><weight>\n    '''\n    rel_mapping = load_merge_relation()\n    num_lines = sum(1 for line in open(cpnet_path, 'r', encoding='utf-8'))\n    concept_net_vocab = []\n    concept_seens = set()\n    with open(cpnet_path,'r', encoding='utf-8') as fin, open(output_path,\"w\", encoding='utf-8') as fout:\n        for line in tqdm(fin, total = num_lines):\n            tokens = line.strip().split(\"\\t\")\n            if tokens[2].startswith('c/en/') and tokens[3].startswith('c/en/'):\n                rel = tokens[1].split(\"/\")[-1].lower()\n                head = del_pos(tokens[2]).split(\"/\")[-1].lower()\n                tail = del_pos(tokens[3]).split(\"/\")[-1].lower()\n                if not head.replace(\"_\", \"\").replace(\"-\", \"\").isalpha():\n                    continue\n                if not tail.replace(\"_\", \"\").replace(\"-\", \"\").isalpha():\n                    continue\n                if rel not in rel_mapping:\n                    continue\n                # maps relation to pre-defined relation\n                rel = rel_mapping[rel]\n                if rel.startswith(\"*\"):\n                    # means reverse part\n                    head, tail, rel = tail, head, rel[1:]\n                # load to dic format\n                data = json.loads(tokens[4])\n                # write into new csv file\n                fout.write('\\t'.join([rel,head,tail, str(data[\"weight\"])]) + \"\\n\")\n                for w in [head, tail]:\n                    if w not in concept_seens:\n                        concept_seens.add(w)\n                        concept_net_vocab.append(w)\n    with open(output_vocab_path,\"w\") as fout:\n        for word in concept_net_vocab:\n            fout.write(word + \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:57:29.318737Z","iopub.execute_input":"2022-05-03T05:57:29.319057Z","iopub.status.idle":"2022-05-03T05:57:29.335564Z","shell.execute_reply.started":"2022-05-03T05:57:29.319022Z","shell.execute_reply":"2022-05-03T05:57:29.334493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def construct_graph(cpnet_csv_path, cpnet_vocab_path, output_path, prune = True):\n    '''\n    This function create the graph structure, just like compgcn and gat,\n    create the basic graph structure\n    '''\n    # get the stopwords\n    nltk.download('stopwords', quiet=True)\n    nltk_stopwords = nltk.corpus.stopwords.words('english')\n    nltk_stopwords += [\"like\", \"gone\", \"did\", \"going\", \"would\", \"could\",\n                       \"get\", \"in\", \"up\", \"may\", \"wanter\"]  \n    blacklist = set([\"uk\", \"us\", \"take\", \"make\", \"object\", \"person\", \"people\"])\n    # create mapping\n    \n    with open(cpnet_vocab_path,\"r\", encoding= 'utf-8') as fin:\n        id2concept = [w.strip() for w in fin]\n    concept2id = {w: i for i, w in enumerate(id2concept)}\n\n    id2relation = merged_relations\n    relation2id = {r: i for i, r in enumerate(id2relation)}\n    # create multidigraph with nx (just like compgcn graph)\n    graph = nx.MultiDiGraph()\n    nrow = sum(1 for _ in open(cpnet_csv_path, 'r', encoding='utf-8'))\n    with open(cpnet_csv_path, \"r\", encoding=\"utf8\") as fin:\n\n        def not_save(cpt):\n            if cpt in blacklist:\n                return True\n            '''originally phrases like \"branch out\" would not be kept in the graph'''\n            return False\n        seen_set = set()\n        for line in tqdm(fin, total = nrow):\n            ls = line.strip().split('\\t')\n            rel = relation2id[ls[0]]\n            subj = concept2id[ls[1]]\n            obj = concept2id[ls[2]]\n            weight = float(ls[3])\n            if prune and (not_save(ls[1]) or not_save(ls[2]) or id2relation[rel] == \"hascontext\"):\n                continue\n            # remove loops in this case\n            if subj == obj:\n                continue\n            if (subj, rel, obj) not in seen_set:\n                # add direction\n                graph.add_edge(subj,obj, rel= rel, weight = weight)\n                seen_set.add((subj,rel,obj))\n                graph.add_edge(obj, subj, rel=rel + len(relation2id), weight=weight)\n                seen_set.add((obj, subj, rel + len(relation2id)))\n    nx.write_gpickle(graph, output_path)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-03T05:57:29.952662Z","iopub.execute_input":"2022-05-03T05:57:29.953668Z","iopub.status.idle":"2022-05-03T05:57:29.970447Z","shell.execute_reply.started":"2022-05-03T05:57:29.953611Z","shell.execute_reply":"2022-05-03T05:57:29.969421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}