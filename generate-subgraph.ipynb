{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport networkx as nx\nimport itertools\nimport json\nfrom tqdm import tqdm\nimport numpy as np\nfrom scipy import sparse\nimport pickle\nfrom scipy.sparse import csr_matrix, coo_matrix\nfrom multiprocessing import Pool\nfrom collections import OrderedDict\nfrom transformers import RobertaTokenizer, RobertaForMaskedLM","metadata":{"execution":{"iopub.status.busy":"2022-05-04T07:28:22.438101Z","iopub.execute_input":"2022-05-04T07:28:22.438712Z","iopub.status.idle":"2022-05-04T07:28:30.213502Z","shell.execute_reply.started":"2022-05-04T07:28:22.438595Z","shell.execute_reply":"2022-05-04T07:28:30.212349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_relations = [\n    'antonym',\n    'atlocation',\n    'capableof',\n    'causes',\n    'createdby',\n    'isa',\n    'desires',\n    'hassubevent',\n    'partof',\n    'hascontext',\n    'hasproperty',\n    'madeof',\n    'notcapableof',\n    'notdesires',\n    'receivesaction',\n    'relatedto',\n    'usedfor',\n]","metadata":{"execution":{"iopub.status.busy":"2022-05-04T07:28:30.216357Z","iopub.execute_input":"2022-05-04T07:28:30.216993Z","iopub.status.idle":"2022-05-04T07:28:30.223472Z","shell.execute_reply.started":"2022-05-04T07:28:30.216945Z","shell.execute_reply":"2022-05-04T07:28:30.222371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(cpnet_vocab_path):\n    with open(cpnet_vocab_path, \"r\", encoding=\"utf-8\") as fin:\n        id2cpt = [line.strip() for line in fin]\n    cpt2id = {w:i for i, w in enumerate(id2cpt)}\n    id2rel = merged_relations\n    rel2id = {w:i for i, w in enumerate(id2rel)}\n    return id2cpt, cpt2id, id2rel, rel2id\n#id2concept, concept2id, id2relation, relation2id = load_data(\"../input/cp-net-en/CPnet_en/concept.txt\")","metadata":{"execution":{"iopub.status.busy":"2022-05-04T07:28:30.225183Z","iopub.execute_input":"2022-05-04T07:28:30.225817Z","iopub.status.idle":"2022-05-04T07:28:30.242888Z","shell.execute_reply.started":"2022-05-04T07:28:30.225771Z","shell.execute_reply":"2022-05-04T07:28:30.241712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load concept net data\ndef load_cpnet(cpnet_graph_path):\n    graph = nx.read_gpickle(cpnet_graph_path)\n    cpnet_simple = nx.Graph()\n    # example: 0 1 {'rel': 0, 'weight': 1.0}\n    for u,v,data in graph.edges(data=True):\n        w = data[\"weight\"] if \"weight\" in data else 1.0\n        if cpnet_simple.has_edge(u,v):\n            cpnet_simple[u][v][\"weight\"] +=w\n        else:\n            cpnet_simple.add_edge(u,v,weight = w)\n    return cpnet_simple, graph\n# cpnet_simple, cpnet = load_cpnet(\"../input/cp-net-en/CPnet_en/conceptnet.en.pruned.graph\")","metadata":{"execution":{"iopub.status.busy":"2022-05-04T07:28:30.246204Z","iopub.execute_input":"2022-05-04T07:28:30.246735Z","iopub.status.idle":"2022-05-04T07:28:30.254673Z","shell.execute_reply.started":"2022-05-04T07:28:30.246683Z","shell.execute_reply":"2022-05-04T07:28:30.253482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# sentence = \"hello world!\"\n# model = AutoModel.from_pretrained(\"bert-base-uncased\")\n# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2022-05-04T07:28:30.297273Z","iopub.execute_input":"2022-05-04T07:28:30.297617Z","iopub.status.idle":"2022-05-04T07:28:30.304004Z","shell.execute_reply.started":"2022-05-04T07:28:30.297574Z","shell.execute_reply":"2022-05-04T07:28:30.302474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input_ids= tokenizer.encode(sentence)\n# max_len = 15\n# input_ids += [tokenizer.pad_token_id]*(max_len - len(input_ids))\n# mask = (torch.tensor(input_ids)!=tokenizer.pad_token_id).long()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T07:28:30.306115Z","iopub.execute_input":"2022-05-04T07:28:30.306904Z","iopub.status.idle":"2022-05-04T07:28:30.313674Z","shell.execute_reply.started":"2022-05-04T07:28:30.306857Z","shell.execute_reply":"2022-05-04T07:28:30.312716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def concepts_to_adj_matrices_2hop_all_pair__use_LM__Part1(data, cpnet_simple):\n    '''\n    This function generate the adj list for each concepts\n    '''\n    q_ids, ans_ids, qa_data = data\n#     print(\"qids\", q_ids)\n#     print(\"ans_ids\", ans_ids)\n    qa_nodes = set(q_ids) | set(ans_ids)\n#     print(\"qa_nodes\", qa_nodes)\n    extra_nodes = set()\n    for qid in qa_nodes:\n        for aid in qa_nodes:\n            if qid != aid and qid in cpnet_simple.nodes and aid in cpnet_simple.nodes:\n                # qid one-hop adj ls\n#                 print(cpnet_simple[qid])\n                # ans one-hop adj ls\n#                 print(cpnet_simple[aid])\n                # get the intersection of each concept one hop neightbour\n                extra_nodes |= set(cpnet_simple[qid]) & set(cpnet_simple[aid])\n    # remove already exist qa part\n    extra_nodes = extra_nodes - qa_nodes\n    return (sorted(q_ids), sorted(ans_ids), qa_data, sorted(extra_nodes))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T07:28:30.317587Z","iopub.execute_input":"2022-05-04T07:28:30.317912Z","iopub.status.idle":"2022-05-04T07:28:30.335761Z","shell.execute_reply.started":"2022-05-04T07:28:30.317869Z","shell.execute_reply":"2022-05-04T07:28:30.334696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get relevance score\ndef get_relevance_score(cids, question, id2concept, tokenizer, model):\n    '''\n    This function return the relevance score for each concepts\n    input:\n        cids: concept ids\n        question: qa context\n        id2concept: id2concept dict\n        tokenizer: huggingface tokenizer\n        model: pretrained language model\n    '''\n    cids = cids[:]\n    # add QA context node\n    # which is the LM encoding represent as z in paper\n    cids.insert(0, -1)\n    sents, scores = [], []\n    # here create all the sentence pair as: question,answer, and do the MLM per each sentence, to get the relevance score per each concept\n    for cid in cids:\n        if cid == -1:\n            # if added\n            sent = question.lower()\n        else:\n            # if true concepts\n            sent = \"{}{}.\".format(question.lower,\" \".join(id2concept[cid].split(\"_\")))\n        sent = tokenizer.encode(sent, add_special_tokens = True)\n        sents.append(sent)\n    num_cids = len(cids)\n    cur_idx = 0\n    batch_size = 50\n    # get score\n    while cur_idx < num_cids:\n        # prepare for each batch\n        input_ids = sents[cur_idx:cur_idx+batch_size]\n        max_len = max([len(seq) for seq in input_ids])\n        # add padding\n        for i, ids in enumerate(input_ids):\n            ids += [tokenizer.pad_token_id] * (max_len - len(ids))\n            input_ids[i] = ids\n        input_ids = torch.tensor(input_ids).cuda()# shape is [bs, max_len]\n        mask = (input_ids != tokenizer.pad_token_id).long()# shape is [bs, max_len]\n        #pass the forward for pretrained language model\n        with torch.no_grad():\n            \n            output = model(input_ids, attention_mask = mask, masked_lm_labels=input_ids)\n            # use loss as score\n            loss = output[0]\n            _scores = list(-loss.detach().cpu().numpy())\n        scores += _scores\n        cur_idx +=batch_size\n    assert len(sents) == len(scores) == len(cids)\n    cid2score = OrderedDict(sorted(list(zip(cids, scores)), key=lambda x: -x[1]))# score from high to low\n    return cid2score","metadata":{"execution":{"iopub.status.busy":"2022-05-04T07:28:30.33986Z","iopub.execute_input":"2022-05-04T07:28:30.340579Z","iopub.status.idle":"2022-05-04T07:28:30.371132Z","shell.execute_reply.started":"2022-05-04T07:28:30.340529Z","shell.execute_reply":"2022-05-04T07:28:30.368239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RobertaForMaskedLMwithLoss(RobertaForMaskedLM):\n    #\n    def __init__(self, config):\n        super().__init__(config)\n    #\n    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, masked_lm_labels=None):\n        #\n        assert attention_mask is not None\n        outputs = self.roberta(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, position_ids=position_ids, head_mask=head_mask)\n        sequence_output = outputs[0] #hidden_states of final layer (batch_size, sequence_length, hidden_size)\n        prediction_scores = self.lm_head(sequence_output)\n#         print(prediction_scores.shape)\n#         print(sequence_output.shape)\n        \n        outputs = (prediction_scores, sequence_output) + outputs[2:]\n#         print(len(outputs))\n        if masked_lm_labels is not None:\n            loss_fct = torch.nn.CrossEntropyLoss(reduction='none')\n            bsize, seqlen = input_ids.size()\n#             print(\"evalutaion shape\",prediction_scores.view(-1, self.config.vocab_size).shape)\n#             print(\"labels shape\",masked_lm_labels.view(-1).shape)\n#             print(\"num_class\", torch.unique(masked_lm_labels.view(-1)).shape)\n#             print(\"class_type\", torch.unique(masked_lm_labels.view(-1)))\n#             print(\"cross entropy shape\", loss_fct(prediction_scores.view(-1, self.config.vocab_size), masked_lm_labels.view(-1)).shape)\n            #这里很奇怪，其评分用的应该是 masked LM\n            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), masked_lm_labels.view(-1)).view(bsize, seqlen)\n            #print(\"loss shape\", masked_lm_loss.shape)\n            masked_lm_loss = (masked_lm_loss * attention_mask).sum(dim=1)\n            outputs = (masked_lm_loss,) + outputs\n            # (masked_lm_loss), prediction_scores, sequence_output, (hidden_states), (attentions)\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2022-05-04T07:40:21.465337Z","iopub.execute_input":"2022-05-04T07:40:21.465687Z","iopub.status.idle":"2022-05-04T07:40:21.480383Z","shell.execute_reply.started":"2022-05-04T07:40:21.465654Z","shell.execute_reply":"2022-05-04T07:40:21.47939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def concepts_to_adj_matrices_2hop_all_pair__use_LM__Part2(data, id2concept):\n    q_ids, ans_ids, qa_data, extra_nodes = data\n    model = RobertaForMaskedLMwithLoss.from_pretrained(\"roberta-large\").cuda()\n    model.eval()\n    tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")\n    cid2score = get_relevance_score(q_ids + ans_ids + extra_nodes, qa_data,id2concept, tokenizer, model)\n    print(cid2score)\n    return (q_ids, ans_ids, qa_data, extra_nodes, cid2score)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T07:28:30.411597Z","iopub.execute_input":"2022-05-04T07:28:30.411996Z","iopub.status.idle":"2022-05-04T07:28:30.431531Z","shell.execute_reply.started":"2022-05-04T07:28:30.411949Z","shell.execute_reply":"2022-05-04T07:28:30.42552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def concepts2adj(node_ids, id2relation,cpnet ):\n    cids = np.array(node_ids, dtype=np.int32)\n    n_rel = len(id2relation)\n    n_node = cids.shape[0]\n    adj = np.zeros((n_rel, n_node, n_node), dtype=np.uint8)\n    for s in range(n_node):\n        for t in range(n_node):\n            s_c, t_c = cids[s], cids[t]\n            if cpnet.has_edge(s_c, t_c):\n                for e_attr in cpnet[s_c][t_c].values():\n                    if e_attr['rel'] >= 0 and e_attr['rel'] < n_rel:\n                        adj[e_attr['rel']][s][t] = 1\n    # cids += 1  # note!!! index 0 is reserved for padding\n    adj = coo_matrix(adj.reshape(-1, n_node))\n    return adj, cids\ndef concepts_to_adj_matrices_2hop_all_pair__use_LM__Part3(data, id2relation, cpnet):\n    q_ids, ans_ids, qa_data, extra_nodes, cid2scores = data\n    schema_graph = q_ids + ans_ids + sorted(extra_nodes, key = lambda x: -cid2scores[x])\n    # get qmask and amask\n    qmask = np.arange(len(schema_graph)) < len(q_ids)\n    amask = (np.arange(len(schema_graph)) >= len(q_ids)) & (np.arange(len(schema_graph)) < len(q_ids) + len(ans_ids))\n    adj, concepts = concepts2adj(schema_graph, id2relation, cpnet)\n    return {\"adj\": adj, \"concepts\":concepts, \"qmask\":qmask, \"amask\":amask, \"cid2score\":cid2scores}","metadata":{"execution":{"iopub.status.busy":"2022-05-04T08:08:01.549724Z","iopub.execute_input":"2022-05-04T08:08:01.550212Z","iopub.status.idle":"2022-05-04T08:08:01.562352Z","shell.execute_reply.started":"2022-05-04T08:08:01.550176Z","shell.execute_reply":"2022-05-04T08:08:01.561149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_adj_data_from_grounded_concepts__use_LM(grounded_path, cpnet_graph_path, cpnet_vocab_path, output_path, num_processes):\n    \"\"\"\n    This function will save\n        (1) adjacency matrics (each in the form of a (R*N, N) coo sparse matrix)\n        (2) concepts ids\n        (3) qmask that specifices whether a node is a question concept\n        (4) amask that specifices whether a node is an answer concept\n        (5) cid2score that maps a concept id to its relevance score given the QA context\n    \"\"\"\n    print(f'generating adj data for {grounded_path}...')\n    id2concept, concept2id, id2relation, relation2id = load_data(cpnet_vocab_path)    \n    cpnet_simple, cpnet = load_cpnet(cpnet_graph_path)\n    qa_data = []\n    statement_path = grounded_path.replace('grounded', 'statement')\n    \n    # ---------------------------------- Get q_concept ids, answer_concept ids, question-answer description\n    with open(grounded_path,'r',encoding='utf-8') as fin_ground, open(statement_path,'r', encoding='utf-8') as fin_state:\n        lines_ground = fin_ground.readlines()\n        lines_state = fin_state.readlines()\n        print(lines_ground[0], lines_state[0])\n        assert len(lines_ground) % len(lines_state) == 0\n        # number of choices per question\n        num_choice = len(lines_ground) // len(lines_state)\n        for j, line in enumerate(lines_ground):\n            dic = json.loads(line)\n            # get question concept and answer concept mapping idx\n            qc_ids = set(concept2id[c] for c in dic[\"qc\"])\n            answers_ids = set(concept2id[c] for c in dic[\"ac\"])\n            # remove answer ids in question ids\n            qc_ids = qc_ids - answers_ids\n            # get corresponding source text ids\n            statement_obj = json.loads(lines_state[j//num_choice])\n            qa_context = \"{}{}.\".format(statement_obj['question'][\"stem\"],dic[\"ans\"])\n            # append it \n            qa_data.append((qc_ids, answers_ids, qa_context))\n    # test\n    qids, ansids, context, intersect_ = concepts_to_adj_matrices_2hop_all_pair__use_LM__Part1(qa_data[0], cpnet_simple)\n    qids, ansids, context, intersect_,cid2score = concepts_to_adj_matrices_2hop_all_pair__use_LM__Part2((qids, ansids, context, intersect_),id2concept)\n    res = concepts_to_adj_matrices_2hop_all_pair__use_LM__Part3((qids, ansids, context, intersect_,cid2score), id2relation, cpnet)\n    #print(res)\n    # if you want to run all the test, please remove the common here\n    \n#     with Pool(num_processes):\n#         res1 = list(tqdm(p.imap(concepts_to_adj_matrices_2hop_all_pair__use_LM__Part1, qa_data), total=len(qa_data)))\n    \n#     res2 = []\n#     for j, _data in enumerate(res1):\n#         if j % 100 == 0: print (j)\n#         res2.append(concepts_to_adj_matrices_2hop_all_pair__use_LM__Part2(_data))\n\n#     with Pool(num_processes) as p:\n#         res3 = list(tqdm(p.imap(concepts_to_adj_matrices_2hop_all_pair__use_LM__Part3, res2), total=len(res2)))\n\n#     # res is a list of responses\n#     with open(output_path, 'wb') as fout:\n#         pickle.dump(res3, fout)\n\n#     print(f'adj data saved to {output_path}')\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-04T08:08:38.601665Z","iopub.execute_input":"2022-05-04T08:08:38.601947Z","iopub.status.idle":"2022-05-04T08:08:38.615821Z","shell.execute_reply.started":"2022-05-04T08:08:38.601916Z","shell.execute_reply":"2022-05-04T08:08:38.614819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_adj_data_from_grounded_concepts__use_LM(\"../input/csqa-with-subgraph/csqa/grounded/train.grounded.jsonl\", \"../input/cp-net-en/CPnet_en/conceptnet.en.pruned.graph\",\n                                                \"../input/cp-net-en/CPnet_en/concept.txt\",None,None)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T08:08:40.091196Z","iopub.execute_input":"2022-05-04T08:08:40.091516Z","iopub.status.idle":"2022-05-04T08:09:31.380783Z","shell.execute_reply.started":"2022-05-04T08:08:40.091472Z","shell.execute_reply":"2022-05-04T08:09:31.379526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}